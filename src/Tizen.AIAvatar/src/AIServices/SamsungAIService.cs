/*
 * Copyright(c) 2024 Samsung Electronics Co., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.IO;
using System.Linq;
using System.Text.Json;
using System.Threading.Tasks;
using Tizen.Uix.Tts;


namespace Tizen.AIAvatar
{
    /// <summary>
    /// Configuration class for Samsung AI services.
    /// </summary>
    [EditorBrowsable(EditorBrowsableState.Never)]
    public class SamsungAIConfiguration : AIServiceConfiguration
    {
        /// <summary>
        /// Initializes a new instance of the <see cref="SamsungAIConfiguration"/> class with default endpoint settings.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public SamsungAIConfiguration()
        {
            Endpoints = new ServiceEndpoints
            {
                LLMEndpoint = "https://playground-api.sec.samsung.net/api/v1/chat/completions",
                TextToSpeechEndpoint = "OnDevice"
            };
        }

        /// <summary>
        /// Gets or sets the default model to use for LLM services.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public string Model { get; set; } = "chat-65b-32k-1.1.2";

        /// <summary>
        /// Gets or sets the small model version for LLM services.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public string SmallModel { get; set; } = "Gauss.L-1B-0.1.1";
    }

    /// <summary>
    /// Samsung AI Service implementation that provides Text-to-Speech and LLM services.
    /// </summary>
    [EditorBrowsable(EditorBrowsableState.Never)]
    public class SamsungAIService : BaseAIService, ITextToSpeechService, ILLMService
    {
        private readonly SamsungAIConfiguration config;
        private readonly TtsClient ttsHandle;
        private TaskCompletionSource<bool> ttsCompletionSource;

        // Audio-related constants
        private const float audioLengthFactor = 0.16f;
        private const float audioTailLengthFactor = 0.015f;
        private const float audioBufferMultiflier = 2f;

                
        private int audioLength;
        private int desiredBufferLength;
        private int audioTailLength;
        private byte[] recordedBuffer;
        private byte[] audioMainBuffer;
        private List<Byte> audioSyncBuffer;
        private float desiredBufferDuration = audioLengthFactor + audioTailLengthFactor;

        /// <summary>
        /// Occurs when a response is generated by the LLM service.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public event EventHandler<llmResponseEventArgs> ResponseHandler;

        /// <summary>
        /// Occurs when the Text-to-Speech service starts processing.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public event EventHandler<ttsStreamingEventArgs> OnTtsStart;

        /// <summary>
        /// Occurs when the Text-to-Speech service is receiving data.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public event EventHandler<ttsStreamingEventArgs> OnTtsReceiving;

        /// <summary>
        /// Occurs when the Text-to-Speech service finishes processing.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public event EventHandler<ttsStreamingEventArgs> OnTtsFinish;

        /// <summary>
        /// Gets the name of the AI service.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)] 
        public override string ServiceName => "SamsungResearch";

        /// <summary>
        /// Gets the capabilities supported by this AI service.
        /// </summary>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public override ServiceCapabilities Capabilities =>
            ServiceCapabilities.TextToSpeech | ServiceCapabilities.LargeLanguageModel;

        /// <summary>
        /// Initializes a new instance of the <see cref="SamsungAIService"/> class with the specified configuration.
        /// </summary>
        /// <param name="config">The configuration for the Samsung AI Service.</param>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public SamsungAIService(SamsungAIConfiguration config) : base(config)
        {
            this.config = config;

            try
            {
                ttsHandle = new TtsClient();
                ttsHandle.SynthesizedPcm += TtsSynthesizedPCM;
                ttsHandle.PlayingMode = PlayingMode.ByClient;

                ttsHandle.Prepare();

                GetSupportedVoices();
            }
            catch (Exception e)
            {
                throw new Exception($"[ERROR] Failed to prepare TTS {e.Message}");
            }
        }

        /// <summary>
        /// Generates a response from the LLM service asynchronously.
        /// </summary>
        /// <param name="message">The input message to be processed by the LLM.</param>
        /// <param name="options">Optional parameters for customizing the LLM output.</param>
        /// <returns>A task representing the asynchronous operation.</returns>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public async Task GenerateTextAsync(string message, Dictionary<string, object> options = null)
        {
            var client = ClientManager.GetClient(config.Endpoints.LLMEndpoint);

            var request = new RestRequest(Method.Post)
                .AddHeader("Authorization", $"Bearer {config.ApiKey}");

            int taskID = (int)(options?.GetValueOrDefault("TaskID", 0) ?? 0);

            if (options != null && options.TryGetValue("promptFilePath", out var jsonFilePathObj) && jsonFilePathObj is string jsonFilePath)
            {
                // Read JSON file content
                if (File.Exists(jsonFilePath))
                {
                    try
                    {
                        var jsonContent = await File.ReadAllTextAsync(jsonFilePath).ConfigureAwait(false);
                        Prompt prompt = JsonSerializer.Deserialize<Prompt>(jsonContent);
                        var msg = prompt.messages.Last();
                        msg.content = String.Format(msg.content, message);

                        request.AddJsonBody(prompt);
                    }
                    catch (Exception ex)
                    {
                        ResponseHandler?.Invoke(this, new llmResponseEventArgs { TaskID = taskID, Error = ex.Message });
                        return;
                    }
                }
                else
                {
                    ResponseHandler?.Invoke(this, new llmResponseEventArgs { TaskID = taskID, Error = $"File not found: {jsonFilePath}" });
                    return;
                }
            }
            else
            {

                var messages = new List<object>
                {
                    new { role = "user", content = message }
                };
                // Add the default body if no JSON file is provided
                request.AddJsonBody(new
                {
                    model = config.Model,
                    messages = messages,
                    temperature = options?.GetValueOrDefault("temperature", 0.5) ?? 0.5,
                    seed = options?.GetValueOrDefault("seed", 0)
                });
            }

            var response = await client.ExecuteAsync(request).ConfigureAwait(false);
            if (!response.IsSuccessful)
            {
                ResponseHandler?.Invoke(this, new llmResponseEventArgs { TaskID = taskID, Error = response.ErrorMessage });
                return;
            }

            var jsonResponse = JsonSerializer.Deserialize<JsonElement>(response.Content);
            string content = jsonResponse.GetProperty("response").GetProperty("content").GetString();

            ResponseHandler?.Invoke(this, new llmResponseEventArgs { TaskID = taskID, Text = content });
        }

        /// <summary>
        /// Converts the given text to speech asynchronously and returns the audio data.
        /// </summary>
        /// <param name="text">The text to be converted to speech.</param>
        /// <param name="voice">Optional parameter to specify the voice type.</param>
        /// <param name="options">Optional parameters for customizing speech output.</param>
        /// <returns>A task representing the asynchronous operation, with a byte array of the generated audio data.</returns>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public async Task<byte[]> TextToSpeechAsync(string text, string voice = null, Dictionary<string, object> options = null)
        {
            audioSyncBuffer = new List<byte>();

            await TextToSpeechStreamAsync(text,voice, options).ConfigureAwait(false);

            return audioSyncBuffer.ToArray();
        }

        /// <summary>
        /// Streams the given text as speech asynchronously.
        /// </summary>
        /// <param name="text">The text to be converted to speech.</param>
        /// <param name="voice">The voice type to be used for the speech.</param>
        /// <param name="options">Optional parameters for customizing speech output.</param>
        /// <returns>A task representing the asynchronous operation.</returns>
        [EditorBrowsable(EditorBrowsableState.Never)]
        public async Task TextToSpeechStreamAsync(string text, string voice, Dictionary<string, object> options)
        {
            ttsCompletionSource = new TaskCompletionSource<bool>();
            recordedBuffer = Array.Empty<byte>();

            //Option 처리
            SpeedRange speedRange = ttsHandle.GetSpeedRange();
            int speed = speedRange.Normal;
            int voiceType = (int)VoiceType.Auto;

            if (options != null)
            {
                if (options.ContainsKey("speechRate"))
                {
                    float speechRate = (float)(options["speechRate"]) / 2.0f;
                    speed = (int)(speedRange.Min + (speedRange.Max - speedRange.Min) * speechRate);
                }

                if (options.ContainsKey("voiceType"))
                {
                    voiceType = (int)options["voiceType"];
                }
            }
            /////////
            try
            {
                ttsHandle.AddText(text, voice, voiceType, speed);

                ttsHandle.Play();

                await ttsCompletionSource.Task.ConfigureAwait(false);
            }
            catch (Exception ex)
            {
                OnTtsFinish?.Invoke(this, new ttsStreamingEventArgs
                {
                    Text = text,
                    Voice = voice,
                    Error = ex.Message,
                    AudioData = Array.Empty<byte>()
                });
            }
        }

        /// <summary>
        /// Releases all resources used by the AI service.
        /// </summary>
        protected override void Dispose(bool disposing)
        {
            if (disposing)
            {
                ttsHandle?.Dispose();
            }
            base.Dispose(disposing);
        }

        /// <summary>
        /// Handles the PCM data synthesized by the TTS service.
        /// </summary>
        /// <param name="sender">The sender of the event.</param>
        /// <param name="e">The event arguments containing PCM data and other information.</param>
        private void TtsSynthesizedPCM(object sender, SynthesizedPcmEventArgs e)
        {
            try
            {
                switch (e.EventType)
                {
                    case SynthesizedPcmEvent.Start:
                        recordedBuffer = Array.Empty<byte>();

                        audioLength = (int)(audioLengthFactor * e.SampleRate * audioBufferMultiflier);
                        audioTailLength = (int)(audioTailLengthFactor * e.SampleRate  * audioBufferMultiflier);
                        desiredBufferLength = (int)(desiredBufferDuration * e.SampleRate * audioBufferMultiflier);

                        audioMainBuffer = new byte[desiredBufferLength];

                        OnTtsStart?.Invoke(this, new ttsStreamingEventArgs
                        {
                            SampleRate = e.SampleRate,
                            AudioBytes = audioLength,
                            TotalBytes = 0,
                            AudioData = Array.Empty<byte>()
                        });

                        Log.Info("Tizen.AIAvatar", $"TTS Start: UtteranceId={e.UtteranceId}, SampleRate={e.SampleRate}");

                        break;

                    case SynthesizedPcmEvent.Continue:

                        audioSyncBuffer?.AddRange(e.Data);
                        recordedBuffer = recordedBuffer.Concat(e.Data).ToArray();

                        if (recordedBuffer.Length >= desiredBufferLength)
                        {
                            Buffer.BlockCopy(recordedBuffer, 0, audioMainBuffer, 0, desiredBufferLength);
                            OnTtsReceiving?.Invoke(this, new ttsStreamingEventArgs
                            {
                                AudioData = audioMainBuffer,
                                ProcessedBytes = audioMainBuffer.Length
                            });

                            
                            int slicedBufferLength = recordedBuffer.Length - audioLength;
                            byte[] slicedBuffer = new byte[slicedBufferLength];
                            Buffer.BlockCopy(recordedBuffer, audioLength, slicedBuffer, 0, slicedBufferLength);

                            recordedBuffer = slicedBuffer;
                        }

                        break;

                    case SynthesizedPcmEvent.Finish:
                        Log.Info("Tizen.AIAvatar", $"TTS Finish: UtteranceId={e.UtteranceId}");

                        // Send any remaining audio data
                        if (recordedBuffer.Length > 0)
                        {
                            int minBufferSize = Math.Min(desiredBufferLength, recordedBuffer.Length);

                            Array.Clear(audioMainBuffer, 0, desiredBufferLength);
                            Buffer.BlockCopy(recordedBuffer, 0, audioMainBuffer, 0, minBufferSize);
                            OnTtsReceiving?.Invoke(this, new ttsStreamingEventArgs
                            {
                                AudioData = audioMainBuffer,
                                ProcessedBytes = minBufferSize,
                                ProgressPercentage = 100
                            });
                        }

                        OnTtsFinish?.Invoke(this, new ttsStreamingEventArgs
                        {
                            AudioData = Array.Empty<byte>(),
                            TotalBytes = recordedBuffer.Length,
                            ProgressPercentage = 100
                        });

                        ttsCompletionSource?.SetResult(true);
                        break;

                    case SynthesizedPcmEvent.Fail:
                        var error = "TTS synthesis failed";
                        
                        OnTtsFinish?.Invoke(this, new ttsStreamingEventArgs
                        {
                            Error = error,
                            AudioData = Array.Empty<byte>()
                        });

                        ttsCompletionSource?.SetException(new Exception(error));

                        break;

                }
            }
            catch (Exception ex)
            {
                Log.Error("Tizen.AIAvatar", $"Error in TtsSynthesizedPCM: {ex.Message}");
                OnTtsFinish?.Invoke(this, new ttsStreamingEventArgs
                {
                    Error = ex.Message,
                    AudioData = Array.Empty<byte>()
                });
                ttsCompletionSource?.SetException(ex);
            }
        }

        /// <summary>
        /// Retrieves the list of supported voices from the TTS client.
        /// </summary>
        /// <returns>A list of supported voice information.</returns>
        private List<VoiceInfo> GetSupportedVoices()
        {
            var voiceInfoList = new List<VoiceInfo>();

            if (ttsHandle == null)
            {
                Log.Error("Tizen.AIAvatar", $"ttsHandle is null");
                return voiceInfoList;
            }

            var supportedVoices = ttsHandle.GetSupportedVoices();
            foreach (var supportedVoice in supportedVoices)
            {
                Log.Info("Tizen.AIAvatar", $"{supportedVoice.Language} & {supportedVoice.VoiceType} is supported");
                voiceInfoList.Add(new VoiceInfo() { Language = supportedVoice.Language, Type = (VoiceType)supportedVoice.VoiceType });
            }
            return voiceInfoList;
        }

        /// <summary>
        /// Invokes the response handler event with the given event arguments.
        /// </summary>
        /// <param name="e">The response event arguments.</param>
        private void OnResponseHandler(llmResponseEventArgs e)
        {
            ResponseHandler?.Invoke(this, e);
        }
    }
}
